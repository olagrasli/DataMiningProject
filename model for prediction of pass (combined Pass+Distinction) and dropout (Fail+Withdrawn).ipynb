{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_module</th>\n",
       "      <th>code_presentation</th>\n",
       "      <th>id_student</th>\n",
       "      <th>final_result</th>\n",
       "      <th>-25</th>\n",
       "      <th>-24</th>\n",
       "      <th>-23</th>\n",
       "      <th>-22</th>\n",
       "      <th>-21</th>\n",
       "      <th>-20</th>\n",
       "      <th>...</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>11391</td>\n",
       "      <td>Pass</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>28400</td>\n",
       "      <td>Pass</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>30268</td>\n",
       "      <td>Withdrawn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>31604</td>\n",
       "      <td>Pass</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>32885</td>\n",
       "      <td>Pass</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32588</th>\n",
       "      <td>GGG</td>\n",
       "      <td>2014J</td>\n",
       "      <td>2640965</td>\n",
       "      <td>Fail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32589</th>\n",
       "      <td>GGG</td>\n",
       "      <td>2014J</td>\n",
       "      <td>2645731</td>\n",
       "      <td>Distinction</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32590</th>\n",
       "      <td>GGG</td>\n",
       "      <td>2014J</td>\n",
       "      <td>2648187</td>\n",
       "      <td>Pass</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32591</th>\n",
       "      <td>GGG</td>\n",
       "      <td>2014J</td>\n",
       "      <td>2679821</td>\n",
       "      <td>Withdrawn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32592</th>\n",
       "      <td>GGG</td>\n",
       "      <td>2014J</td>\n",
       "      <td>2684003</td>\n",
       "      <td>Distinction</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32593 rows Ã— 299 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      code_module code_presentation  id_student final_result  -25  -24  -23  \\\n",
       "0             AAA             2013J       11391         Pass  0.0  0.0  0.0   \n",
       "1             AAA             2013J       28400         Pass  0.0  0.0  0.0   \n",
       "2             AAA             2013J       30268    Withdrawn  0.0  0.0  0.0   \n",
       "3             AAA             2013J       31604         Pass  0.0  0.0  0.0   \n",
       "4             AAA             2013J       32885         Pass  0.0  0.0  0.0   \n",
       "...           ...               ...         ...          ...  ...  ...  ...   \n",
       "32588         GGG             2014J     2640965         Fail  0.0  0.0  0.0   \n",
       "32589         GGG             2014J     2645731  Distinction  0.0  0.0  0.0   \n",
       "32590         GGG             2014J     2648187         Pass  0.0  0.0  0.0   \n",
       "32591         GGG             2014J     2679821    Withdrawn  0.0  0.0  0.0   \n",
       "32592         GGG             2014J     2684003  Distinction  0.0  0.0  0.0   \n",
       "\n",
       "       -22  -21  -20  ...  260  261  262  263  264  265  266  267  268  269  \n",
       "0      0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "32588  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "32589  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "32590  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "32591  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "32592  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[32593 rows x 299 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clicks = pd.read_csv('stud_dates_click.csv')\n",
    "clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_module</th>\n",
       "      <th>code_presentation</th>\n",
       "      <th>id_student</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>highest_education</th>\n",
       "      <th>imd_band</th>\n",
       "      <th>age_band</th>\n",
       "      <th>num_of_prev_attempts</th>\n",
       "      <th>studied_credits</th>\n",
       "      <th>disability</th>\n",
       "      <th>final_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>11391</td>\n",
       "      <td>M</td>\n",
       "      <td>East Anglian Region</td>\n",
       "      <td>HE Qualification</td>\n",
       "      <td>90-100%</td>\n",
       "      <td>55&lt;=</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>28400</td>\n",
       "      <td>F</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>HE Qualification</td>\n",
       "      <td>20-30%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>30268</td>\n",
       "      <td>F</td>\n",
       "      <td>North Western Region</td>\n",
       "      <td>A Level or Equivalent</td>\n",
       "      <td>30-40%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>Y</td>\n",
       "      <td>Withdrawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>31604</td>\n",
       "      <td>F</td>\n",
       "      <td>South East Region</td>\n",
       "      <td>A Level or Equivalent</td>\n",
       "      <td>50-60%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>32885</td>\n",
       "      <td>F</td>\n",
       "      <td>West Midlands Region</td>\n",
       "      <td>Lower Than A Level</td>\n",
       "      <td>50-60%</td>\n",
       "      <td>0-35</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32588</th>\n",
       "      <td>GGG</td>\n",
       "      <td>2014J</td>\n",
       "      <td>2640965</td>\n",
       "      <td>F</td>\n",
       "      <td>Wales</td>\n",
       "      <td>Lower Than A Level</td>\n",
       "      <td>10-20</td>\n",
       "      <td>0-35</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>N</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32589</th>\n",
       "      <td>GGG</td>\n",
       "      <td>2014J</td>\n",
       "      <td>2645731</td>\n",
       "      <td>F</td>\n",
       "      <td>East Anglian Region</td>\n",
       "      <td>Lower Than A Level</td>\n",
       "      <td>40-50%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>N</td>\n",
       "      <td>Distinction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32590</th>\n",
       "      <td>GGG</td>\n",
       "      <td>2014J</td>\n",
       "      <td>2648187</td>\n",
       "      <td>F</td>\n",
       "      <td>South Region</td>\n",
       "      <td>A Level or Equivalent</td>\n",
       "      <td>20-30%</td>\n",
       "      <td>0-35</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>Y</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32591</th>\n",
       "      <td>GGG</td>\n",
       "      <td>2014J</td>\n",
       "      <td>2679821</td>\n",
       "      <td>F</td>\n",
       "      <td>South East Region</td>\n",
       "      <td>Lower Than A Level</td>\n",
       "      <td>90-100%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>N</td>\n",
       "      <td>Withdrawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32592</th>\n",
       "      <td>GGG</td>\n",
       "      <td>2014J</td>\n",
       "      <td>2684003</td>\n",
       "      <td>F</td>\n",
       "      <td>Yorkshire Region</td>\n",
       "      <td>HE Qualification</td>\n",
       "      <td>50-60%</td>\n",
       "      <td>35-55</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>N</td>\n",
       "      <td>Distinction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32593 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      code_module code_presentation  id_student gender                region  \\\n",
       "0             AAA             2013J       11391      M   East Anglian Region   \n",
       "1             AAA             2013J       28400      F              Scotland   \n",
       "2             AAA             2013J       30268      F  North Western Region   \n",
       "3             AAA             2013J       31604      F     South East Region   \n",
       "4             AAA             2013J       32885      F  West Midlands Region   \n",
       "...           ...               ...         ...    ...                   ...   \n",
       "32588         GGG             2014J     2640965      F                 Wales   \n",
       "32589         GGG             2014J     2645731      F   East Anglian Region   \n",
       "32590         GGG             2014J     2648187      F          South Region   \n",
       "32591         GGG             2014J     2679821      F     South East Region   \n",
       "32592         GGG             2014J     2684003      F      Yorkshire Region   \n",
       "\n",
       "           highest_education imd_band age_band  num_of_prev_attempts  \\\n",
       "0           HE Qualification  90-100%     55<=                     0   \n",
       "1           HE Qualification   20-30%    35-55                     0   \n",
       "2      A Level or Equivalent   30-40%    35-55                     0   \n",
       "3      A Level or Equivalent   50-60%    35-55                     0   \n",
       "4         Lower Than A Level   50-60%     0-35                     0   \n",
       "...                      ...      ...      ...                   ...   \n",
       "32588     Lower Than A Level    10-20     0-35                     0   \n",
       "32589     Lower Than A Level   40-50%    35-55                     0   \n",
       "32590  A Level or Equivalent   20-30%     0-35                     0   \n",
       "32591     Lower Than A Level  90-100%    35-55                     0   \n",
       "32592       HE Qualification   50-60%    35-55                     0   \n",
       "\n",
       "       studied_credits disability final_result  \n",
       "0                  240          N         Pass  \n",
       "1                   60          N         Pass  \n",
       "2                   60          Y    Withdrawn  \n",
       "3                   60          N         Pass  \n",
       "4                   60          N         Pass  \n",
       "...                ...        ...          ...  \n",
       "32588               30          N         Fail  \n",
       "32589               30          N  Distinction  \n",
       "32590               30          Y         Pass  \n",
       "32591               30          N    Withdrawn  \n",
       "32592               30          N  Distinction  \n",
       "\n",
       "[32593 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stud_df = pd.read_csv('./data/studentInfo.csv')\n",
    "stud_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_module</th>\n",
       "      <th>code_presentation</th>\n",
       "      <th>id_student</th>\n",
       "      <th>id_assessment</th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>date_submitted</th>\n",
       "      <th>is_banked</th>\n",
       "      <th>score</th>\n",
       "      <th>marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>11391</td>\n",
       "      <td>1752</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>11391</td>\n",
       "      <td>1753</td>\n",
       "      <td>54.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>11391</td>\n",
       "      <td>1754</td>\n",
       "      <td>117.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>11391</td>\n",
       "      <td>1755</td>\n",
       "      <td>166.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>11391</td>\n",
       "      <td>1756</td>\n",
       "      <td>215.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>24.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173907</th>\n",
       "      <td>GGG</td>\n",
       "      <td>2014J</td>\n",
       "      <td>2684003</td>\n",
       "      <td>37437</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173908</th>\n",
       "      <td>GGG</td>\n",
       "      <td>2014J</td>\n",
       "      <td>2684003</td>\n",
       "      <td>37438</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173909</th>\n",
       "      <td>GGG</td>\n",
       "      <td>2014J</td>\n",
       "      <td>2684003</td>\n",
       "      <td>37439</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173910</th>\n",
       "      <td>GGG</td>\n",
       "      <td>2014J</td>\n",
       "      <td>2684003</td>\n",
       "      <td>37440</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173911</th>\n",
       "      <td>GGG</td>\n",
       "      <td>2014J</td>\n",
       "      <td>2684003</td>\n",
       "      <td>37441</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173912 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       code_module code_presentation  id_student  id_assessment   date  \\\n",
       "0              AAA             2013J       11391           1752   19.0   \n",
       "1              AAA             2013J       11391           1753   54.0   \n",
       "2              AAA             2013J       11391           1754  117.0   \n",
       "3              AAA             2013J       11391           1755  166.0   \n",
       "4              AAA             2013J       11391           1756  215.0   \n",
       "...            ...               ...         ...            ...    ...   \n",
       "173907         GGG             2014J     2684003          37437  173.0   \n",
       "173908         GGG             2014J     2684003          37438  229.0   \n",
       "173909         GGG             2014J     2684003          37439  229.0   \n",
       "173910         GGG             2014J     2684003          37440  229.0   \n",
       "173911         GGG             2014J     2684003          37441  229.0   \n",
       "\n",
       "        weight  date_submitted  is_banked  score  marks  \n",
       "0         10.0              18          0   78.0    7.8  \n",
       "1         20.0              53          0   85.0   17.0  \n",
       "2         20.0             115          0   80.0   16.0  \n",
       "3         20.0             164          0   85.0   17.0  \n",
       "4         30.0             212          0   82.0   24.6  \n",
       "...        ...             ...        ...    ...    ...  \n",
       "173907     0.0             169          0   60.0   60.0  \n",
       "173908     0.0              73          0  100.0  100.0  \n",
       "173909     0.0             150          0   60.0   60.0  \n",
       "173910     0.0             172          0  100.0  100.0  \n",
       "173911     0.0             206          0  100.0  100.0  \n",
       "\n",
       "[173912 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.read_csv('stud_graded_nonGraded_assessment.csv')\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.merge(stud_df, data, on=['code_module', 'code_presentation', 'id_student', 'final_result'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [str(i) for i in range(-25, 270)]\n",
    "# data.groupby('final_result')[cols].mean().T.plot(figsize=(14, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove those student records who has no records on studnet VLE\n",
    "\n",
    "We want to predict the final result of each student based on the interaction with VLE, therefore it better to keep\n",
    "those students records who has atleast some interaction with VLE\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data[cols].sum(axis=1)==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data[cols].sum(axis=1)==0]['final_result'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## It seems 3365 students has no records on studentVLE table\n",
    "\n",
    "From above analysis we see that out of 3365 students, 2988 students Withdrawn, 374 students are Fail and 3 students are Pass.\n",
    "\n",
    "* Withdrawn: In case of withdrawn, It is possible that student register for the course and after some time period student withdrawn from couse without interacting with VLE.  \n",
    "* Fail: In case of Fail, Maybe student register for the course but did not withdrawn till the end of course that why they may have Fail status\n",
    "* Pass: This is exceptional condition, without any interaction with VLE, how studnet get pass, \n",
    "\n",
    "These records will affect the model, therefore We will drop these records for further processing\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[data[cols].sum(axis=1)!=0]\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.groupby('final_result')[cols].mean().T.plot(figsize=(14, 10))\n",
    "# plt.xlabel('Dates')\n",
    "# plt.ylabel('Average click')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "If we compare the two graphs, we can see that the graph of withdraw and Fail is almost identical till 25 days.  After 25 to 75 dyas, the difference is noticable but after 75 days, the gap becomes bigger. \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['final_result'] = data['final_result'].map({'Pass':1, 'Distinction':2, 'Withdrawn':0, 'Fail':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=150\n",
    "query = 'date<{} and weight!=0'.format(days)\n",
    "weighted = score_df.query(query)\n",
    "weighted = weighted.groupby(['code_module', 'code_presentation', 'id_student'])['marks'].sum()\n",
    "# average the weighted grade\n",
    "query = 'date<{} and weight==0'.format(days)\n",
    "non_weighted = score_df.query(query)\n",
    "non_weighted = non_weighted.groupby(['code_module', 'code_presentation', 'id_student'])['marks'].mean()\n",
    "# make one table\n",
    "score_df = pd.merge(weighted, non_weighted, on=['code_module', 'code_presentation', 'id_student'], how='outer')\n",
    "score_df.columns = ['graded', 'non_graded']\n",
    "score_df.fillna(0, inplace=True)\n",
    "# merge score df and clicks df\n",
    "final = pd.merge(clicks, score_df, on=['code_module', 'code_presentation', 'id_student'], how='left')\n",
    "final.fillna(0, inplace=True)\n",
    "final = pd.merge(stud_df, final, on=['code_module', 'code_presentation', 'id_student', 'final_result'], how='inner')\n",
    "final['final_result'] = final['final_result'].map({'Pass':1, 'Distinction':2, 'Withdrawn':0, 'Fail':0})\n",
    "\n",
    "# train_test_split\n",
    "dataX = final.drop(columns='final_result')\n",
    "target = final['final_result']\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, target, test_size=0.2, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, days):\n",
    "    #clicks data\n",
    "    cols = [str(i) for i in range(-25, days)]\n",
    "    X1 = data[cols]\n",
    "    \n",
    "    # demographic data\n",
    "    gen_cols = ['gender', 'region', 'highest_education', 'imd_band', \n",
    "        'age_band', 'num_of_prev_attempts', 'studied_credits', 'disability']\n",
    "    cat_cols = ['gender', 'region', 'highest_education', 'imd_band', 'age_band', 'disability']\n",
    "    X2 = data[gen_cols]\n",
    "    for col in cat_cols:\n",
    "        X2 = pd.concat([X2, pd.get_dummies(X2[col], prefix=col, prefix_sep='_')], axis=1)\n",
    "        X2.drop(columns=col, inplace=True)\n",
    "    \n",
    "    # assignmnet score data\n",
    "    score_cols = ['code_module', 'code_presentation', 'graded', 'non_graded']\n",
    "    X3 = data[score_cols]\n",
    "    for col in score_cols[:2]:\n",
    "        X3 = pd.concat([X3, pd.get_dummies(X3[col], prefix=col, prefix_sep='_')], axis=1)\n",
    "        X3.drop(columns=col, inplace=True)        \n",
    "    \n",
    "    return X1, X2, X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: (26074, 175) (26074, 37) (26074, 13)\n",
      "Test Data:  (6519, 175) (6519, 37) (6519, 13)\n"
     ]
    }
   ],
   "source": [
    "X_train_clicks, X_train_demographics, X_train_score = prepare_data(X_train, days)\n",
    "X_test_clicks, X_test_demographics, X_test_score = prepare_data(X_test, days)\n",
    "print('Train Data:', X_train_clicks.shape, X_train_demographics.shape, X_train_score.shape)\n",
    "print('Test Data: ', X_test_clicks.shape, X_test_demographics.shape, X_test_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import utils\n",
    "y_train_cat = utils.to_categorical(y_train)\n",
    "y_test_cat = utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Conv1D, AveragePooling1D, Flatten, Add, Multiply, Softmax\n",
    "from tensorflow.keras import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(days+25, )))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "demographic = Sequential()\n",
    "demographic.add(Input(shape=(37, )))\n",
    "demographic.add(Dense(128, activation='relu'))\n",
    "demographic.add(Dense(64, activation='relu'))\n",
    "demographic.add(Dense(16, activation='relu'))\n",
    "demographic.add(Dense(3, activation='softmax'))\n",
    "\n",
    "assignmnet = Sequential()\n",
    "assignmnet.add(Input(shape=(13, )))\n",
    "assignmnet.add(Dense(128, activation='relu'))\n",
    "assignmnet.add(Dense(64, activation='relu'))\n",
    "assignmnet.add(Dense(16, activation='relu'))\n",
    "assignmnet.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "demographic.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "assignmnet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# categorical_crossentropy, binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss(history):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2608/2608 - 11s - loss: 0.7643 - accuracy: 0.6997\n",
      "Epoch 2/20\n",
      "2608/2608 - 13s - loss: 0.6122 - accuracy: 0.7528\n",
      "Epoch 3/20\n",
      "2608/2608 - 13s - loss: 0.5788 - accuracy: 0.7590\n",
      "Epoch 4/20\n",
      "2608/2608 - 9s - loss: 0.5594 - accuracy: 0.7660\n",
      "Epoch 5/20\n",
      "2608/2608 - 14s - loss: 0.5464 - accuracy: 0.7692\n",
      "Epoch 6/20\n",
      "2608/2608 - 13s - loss: 0.5186 - accuracy: 0.7739\n",
      "Epoch 7/20\n",
      "2608/2608 - 22s - loss: 0.5000 - accuracy: 0.7795\n",
      "Epoch 8/20\n",
      "2608/2608 - 12s - loss: 0.4752 - accuracy: 0.7845\n",
      "Epoch 9/20\n",
      "2608/2608 - 25s - loss: 0.4570 - accuracy: 0.7914\n",
      "Epoch 10/20\n",
      "2608/2608 - 8s - loss: 0.4359 - accuracy: 0.7973\n",
      "Epoch 11/20\n",
      "2608/2608 - 6s - loss: 0.4297 - accuracy: 0.8023\n",
      "Epoch 12/20\n",
      "2608/2608 - 3s - loss: 0.4119 - accuracy: 0.8159\n",
      "Epoch 13/20\n",
      "2608/2608 - 7s - loss: 0.4029 - accuracy: 0.8215\n",
      "Epoch 14/20\n",
      "2608/2608 - 4s - loss: 0.3891 - accuracy: 0.8251\n",
      "Epoch 15/20\n",
      "2608/2608 - 4s - loss: 0.3792 - accuracy: 0.8321\n",
      "Epoch 16/20\n",
      "2608/2608 - 4s - loss: 0.3694 - accuracy: 0.8385\n",
      "Epoch 17/20\n",
      "2608/2608 - 3s - loss: 0.3558 - accuracy: 0.8426\n",
      "Epoch 18/20\n",
      "2608/2608 - 3s - loss: 0.3533 - accuracy: 0.8453\n",
      "Epoch 19/20\n",
      "2608/2608 - 3s - loss: 0.3466 - accuracy: 0.8497\n",
      "Epoch 20/20\n",
      "2608/2608 - 3s - loss: 0.3363 - accuracy: 0.8530\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80      3616\n",
      "           1       0.64      0.62      0.63      2538\n",
      "           2       0.15      0.24      0.18       365\n",
      "\n",
      "    accuracy                           0.69      6519\n",
      "   macro avg       0.54      0.55      0.54      6519\n",
      "weighted avg       0.71      0.69      0.70      6519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_clicks, y_train_cat, epochs=20, batch_size=10, verbose=2)\n",
    "predict = model.predict(X_test_clicks)\n",
    "predict = np.argmax(predict, axis=1)\n",
    "print(classification_report(predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2608/2608 - 6s - loss: 0.9303 - accuracy: 0.5258\n",
      "Epoch 2/20\n",
      "2608/2608 - 5s - loss: 0.8978 - accuracy: 0.5458\n",
      "Epoch 3/20\n",
      "2608/2608 - 6s - loss: 0.8923 - accuracy: 0.5528\n",
      "Epoch 4/20\n",
      "2608/2608 - 5s - loss: 0.8908 - accuracy: 0.5502\n",
      "Epoch 5/20\n",
      "2608/2608 - 6s - loss: 0.8894 - accuracy: 0.5529\n",
      "Epoch 6/20\n",
      "2608/2608 - 14s - loss: 0.8886 - accuracy: 0.5524\n",
      "Epoch 7/20\n",
      "2608/2608 - 7s - loss: 0.8877 - accuracy: 0.5541\n",
      "Epoch 8/20\n",
      "2608/2608 - 6s - loss: 0.8881 - accuracy: 0.5550\n",
      "Epoch 9/20\n",
      "2608/2608 - 6s - loss: 0.8872 - accuracy: 0.5573\n",
      "Epoch 10/20\n",
      "2608/2608 - 7s - loss: 0.8870 - accuracy: 0.5543\n",
      "Epoch 11/20\n",
      "2608/2608 - 9s - loss: 0.8863 - accuracy: 0.5533\n",
      "Epoch 12/20\n",
      "2608/2608 - 9s - loss: 0.8858 - accuracy: 0.5531\n",
      "Epoch 13/20\n",
      "2608/2608 - 9s - loss: 0.8847 - accuracy: 0.5571\n",
      "Epoch 14/20\n",
      "2608/2608 - 9s - loss: 0.8848 - accuracy: 0.5552\n",
      "Epoch 15/20\n",
      "2608/2608 - 11s - loss: 0.8846 - accuracy: 0.5542\n",
      "Epoch 16/20\n",
      "2608/2608 - 7s - loss: 0.8844 - accuracy: 0.5527\n",
      "Epoch 17/20\n",
      "2608/2608 - 6s - loss: 0.8837 - accuracy: 0.5563\n",
      "Epoch 18/20\n",
      "2608/2608 - 6s - loss: 0.8836 - accuracy: 0.5552\n",
      "Epoch 19/20\n",
      "2608/2608 - 6s - loss: 0.8835 - accuracy: 0.5563\n",
      "Epoch 20/20\n",
      "2608/2608 - 6s - loss: 0.8834 - accuracy: 0.5567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.59      0.68      4552\n",
      "           1       0.37      0.47      0.41      1967\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.56      6519\n",
      "   macro avg       0.39      0.35      0.36      6519\n",
      "weighted avg       0.66      0.56      0.60      6519\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramesh/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "history = demographic.fit(X_train_demographics, y_train_cat, epochs=20, batch_size=10, verbose=2)\n",
    "predict = demographic.predict(X_test_demographics)\n",
    "predict = np.argmax(predict, axis=1)\n",
    "print(classification_report(predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "734/734 - 1s - loss: 0.6560 - accuracy: 0.7201 - val_loss: 0.6058 - val_accuracy: 0.7427\n",
      "Epoch 2/15\n",
      "734/734 - 1s - loss: 0.5783 - accuracy: 0.7429 - val_loss: 0.5689 - val_accuracy: 0.7446\n",
      "Epoch 3/15\n",
      "734/734 - 1s - loss: 0.5715 - accuracy: 0.7456 - val_loss: 0.5872 - val_accuracy: 0.7508\n",
      "Epoch 4/15\n",
      "734/734 - 1s - loss: 0.5671 - accuracy: 0.7467 - val_loss: 0.5586 - val_accuracy: 0.7573\n",
      "Epoch 5/15\n",
      "734/734 - 1s - loss: 0.5594 - accuracy: 0.7495 - val_loss: 0.5816 - val_accuracy: 0.7396\n",
      "Epoch 6/15\n",
      "734/734 - 1s - loss: 0.5615 - accuracy: 0.7505 - val_loss: 0.5549 - val_accuracy: 0.7546\n",
      "Epoch 7/15\n",
      "734/734 - 1s - loss: 0.5535 - accuracy: 0.7522 - val_loss: 0.5655 - val_accuracy: 0.7462\n",
      "Epoch 8/15\n",
      "734/734 - 1s - loss: 0.5524 - accuracy: 0.7513 - val_loss: 0.5549 - val_accuracy: 0.7523\n",
      "Epoch 9/15\n",
      "734/734 - 1s - loss: 0.5504 - accuracy: 0.7534 - val_loss: 0.5569 - val_accuracy: 0.7523\n",
      "Epoch 10/15\n",
      "734/734 - 1s - loss: 0.5468 - accuracy: 0.7529 - val_loss: 0.5492 - val_accuracy: 0.7569\n",
      "Epoch 11/15\n",
      "734/734 - 1s - loss: 0.5474 - accuracy: 0.7530 - val_loss: 0.5507 - val_accuracy: 0.7523\n",
      "Epoch 12/15\n",
      "734/734 - 1s - loss: 0.5452 - accuracy: 0.7533 - val_loss: 0.5582 - val_accuracy: 0.7423\n",
      "Epoch 13/15\n",
      "734/734 - 1s - loss: 0.5432 - accuracy: 0.7548 - val_loss: 0.5491 - val_accuracy: 0.7577\n",
      "Epoch 14/15\n",
      "734/734 - 1s - loss: 0.5420 - accuracy: 0.7550 - val_loss: 0.5479 - val_accuracy: 0.7512\n",
      "Epoch 15/15\n",
      "734/734 - 1s - loss: 0.5423 - accuracy: 0.7530 - val_loss: 0.5614 - val_accuracy: 0.7492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84      3075\n",
      "           1       0.87      0.63      0.73      3421\n",
      "           2       0.03      0.78      0.06        23\n",
      "\n",
      "    accuracy                           0.75      6519\n",
      "   macro avg       0.56      0.77      0.54      6519\n",
      "weighted avg       0.83      0.75      0.78      6519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = assignmnet.fit(X_train_score, y_train_cat, validation_split=0.1, epochs=15, batch_size=32, verbose=2)\n",
    "predict = assignmnet.predict(X_test_score)\n",
    "predict = np.argmax(predict, axis=1)\n",
    "print(classification_report(predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_67 (InputLayer)           [(None, 125)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_68 (InputLayer)           [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_264 (Dense)               (None, 128)          16128       input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_268 (Dense)               (None, 128)          1792        input_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_265 (Dense)               (None, 64)           8256        dense_264[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_269 (Dense)               (None, 64)           8256        dense_268[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_266 (Dense)               (None, 16)           1040        dense_265[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_270 (Dense)               (None, 16)           1040        dense_269[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_267 (Dense)               (None, 6)            102         dense_266[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_271 (Dense)               (None, 6)            102         dense_270[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 6)            0           dense_267[0][0]                  \n",
      "                                                                 dense_271[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_272 (Dense)               (None, 3)            21          add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "softmax_11 (Softmax)            (None, 3)            0           dense_272[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 36,737\n",
      "Trainable params: 36,737\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# lets combine all three models\n",
    "input_clik= Input(shape=(days+25, ))\n",
    "x1 = Dense(128, activation='relu')(input_clik)\n",
    "x1 = Dense(64, activation='relu')(x1)\n",
    "x1 = Dense(16, activation='relu')(x1)\n",
    "out1 = Dense(6, activation='relu')(x1)\n",
    "\n",
    "# input_demo = Input(shape=(37, ))\n",
    "# x2 = Dense(128, activation='relu')(input_demo)\n",
    "# x2 = Dense(64, activation='relu')(x2)\n",
    "# x2 = Dense(16, activation='relu')(x2)\n",
    "# out2 = Dense(3, activation='relu')(x2)\n",
    "\n",
    "input_assig = Input(shape=(13, ))\n",
    "x3 = Dense(128, activation='relu')(input_assig)\n",
    "x3 = Dense(64, activation='relu')(x3)\n",
    "x3 = Dense(16, activation='relu')(x3)\n",
    "out3 = Dense(6, activation='relu')(x3)\n",
    "\n",
    "out4 = Add()([out1, out3])\n",
    "out4 = Dense(3, activation='softmax')(out4)\n",
    "out = Softmax()(out4)\n",
    "\n",
    "combine_model = Model(inputs=[input_clik, input_assig], outputs=out)\n",
    "print(combine_model.summary())\n",
    "combine_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "815/815 - 1s - loss: 0.8465 - accuracy: 0.6971\n",
      "Epoch 2/20\n",
      "815/815 - 1s - loss: 0.8054 - accuracy: 0.7409\n",
      "Epoch 3/20\n",
      "815/815 - 1s - loss: 0.7982 - accuracy: 0.7471\n",
      "Epoch 4/20\n",
      "815/815 - 1s - loss: 0.7930 - accuracy: 0.7534\n",
      "Epoch 5/20\n",
      "815/815 - 1s - loss: 0.7912 - accuracy: 0.7559\n",
      "Epoch 6/20\n",
      "815/815 - 1s - loss: 0.7877 - accuracy: 0.7601\n",
      "Epoch 7/20\n",
      "815/815 - 1s - loss: 0.7830 - accuracy: 0.7652\n",
      "Epoch 8/20\n",
      "815/815 - 1s - loss: 0.7805 - accuracy: 0.7675\n",
      "Epoch 9/20\n",
      "815/815 - 2s - loss: 0.7783 - accuracy: 0.7710\n",
      "Epoch 10/20\n",
      "815/815 - 2s - loss: 0.7734 - accuracy: 0.7754\n",
      "Epoch 11/20\n",
      "815/815 - 2s - loss: 0.7700 - accuracy: 0.7793\n",
      "Epoch 12/20\n",
      "815/815 - 2s - loss: 0.7665 - accuracy: 0.7825\n",
      "Epoch 13/20\n",
      "815/815 - 3s - loss: 0.7632 - accuracy: 0.7867\n",
      "Epoch 14/20\n",
      "815/815 - 3s - loss: 0.7572 - accuracy: 0.7926\n",
      "Epoch 15/20\n",
      "815/815 - 2s - loss: 0.7574 - accuracy: 0.7926\n",
      "Epoch 16/20\n",
      "815/815 - 2s - loss: 0.7520 - accuracy: 0.7978\n",
      "Epoch 17/20\n",
      "815/815 - 2s - loss: 0.7498 - accuracy: 0.8005\n",
      "Epoch 18/20\n",
      "815/815 - 1s - loss: 0.7452 - accuracy: 0.8052\n",
      "Epoch 19/20\n",
      "815/815 - 1s - loss: 0.7468 - accuracy: 0.8036\n",
      "Epoch 20/20\n",
      "815/815 - 1s - loss: 0.7419 - accuracy: 0.8085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe714299df0>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_model.fit([X_train_clicks, X_train_score], y_train_cat, epochs=20, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.50      0.53      3766\n",
      "           1       0.07      0.21      0.10       829\n",
      "           2       0.33      0.10      0.16      1924\n",
      "\n",
      "    accuracy                           0.35      6519\n",
      "   macro avg       0.32      0.27      0.26      6519\n",
      "weighted avg       0.42      0.35      0.36      6519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict = combine_model.predict([X_test_clicks, X_test_score])\n",
    "predict = np.argmax(predict, axis=1)\n",
    "print(classification_report(predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2472, 0: 3442, 2: 605})"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets try with CNN1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train_clicks)\n",
    "X_test = np.array(X_test_clicks)\n",
    "\n",
    "# reshape\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Input(shape=(days+25, 1)))\n",
    "model2.add(Conv1D(32, kernel_size=2, activation='relu'))\n",
    "model2.add(AveragePooling1D(2))\n",
    "model2.add(Conv1D(64, kernel_size=2, activation='relu'))\n",
    "model2.add(AveragePooling1D(2))\n",
    "model2.add(Conv1D(128, kernel_size=2, activation='relu'))\n",
    "model2.add(AveragePooling1D(2))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128,  activation='relu'))\n",
    "model2.add(Dense(64,  activation='relu'))\n",
    "model2.add(Dense(32,  activation='relu'))\n",
    "model2.add(Dense(3,  activation='softmax')) #softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "815/815 - 11s - loss: 0.2653 - accuracy: 0.9038\n",
      "Epoch 2/20\n",
      "815/815 - 10s - loss: 0.1859 - accuracy: 0.9327\n",
      "Epoch 3/20\n",
      "815/815 - 10s - loss: 0.1415 - accuracy: 0.9493\n",
      "Epoch 4/20\n",
      "815/815 - 10s - loss: 0.1066 - accuracy: 0.9649\n",
      "Epoch 5/20\n",
      "815/815 - 10s - loss: 0.0788 - accuracy: 0.9740\n",
      "Epoch 6/20\n",
      "815/815 - 10s - loss: 0.0665 - accuracy: 0.9776\n",
      "Epoch 7/20\n",
      "815/815 - 10s - loss: 0.0596 - accuracy: 0.9805\n",
      "Epoch 8/20\n",
      "815/815 - 13s - loss: 0.0625 - accuracy: 0.9825\n",
      "Epoch 9/20\n",
      "815/815 - 15s - loss: 0.0378 - accuracy: 0.9886\n",
      "Epoch 10/20\n",
      "815/815 - 11s - loss: 0.0435 - accuracy: 0.9866\n",
      "Epoch 11/20\n",
      "815/815 - 11s - loss: 0.0399 - accuracy: 0.9878\n",
      "Epoch 12/20\n",
      "815/815 - 10s - loss: 0.0375 - accuracy: 0.9886\n",
      "Epoch 13/20\n",
      "815/815 - 15s - loss: 0.0336 - accuracy: 0.9894\n",
      "Epoch 14/20\n",
      "815/815 - 12s - loss: 0.0340 - accuracy: 0.9887\n",
      "Epoch 15/20\n",
      "815/815 - 11s - loss: 0.0283 - accuracy: 0.9916\n",
      "Epoch 16/20\n",
      "815/815 - 12s - loss: 0.0437 - accuracy: 0.9876\n",
      "Epoch 17/20\n",
      "815/815 - 12s - loss: 0.0247 - accuracy: 0.9925\n",
      "Epoch 18/20\n",
      "815/815 - 11s - loss: 0.0249 - accuracy: 0.9927\n",
      "Epoch 19/20\n",
      "815/815 - 12s - loss: 0.0313 - accuracy: 0.9903\n",
      "Epoch 20/20\n",
      "815/815 - 12s - loss: 0.0231 - accuracy: 0.9937\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "hist = model2.fit(X_train, y_train_cat, epochs=20, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-966e30d1fc8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoches'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(hist.history['accuracy'], label='Train')\n",
    "plt.plot(hist.history['val_accuracy'], label='Validation')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoches')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2941</td>\n",
       "      <td>325</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>457</td>\n",
       "      <td>1934</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>213</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1    2\n",
       "0  2941   325   43\n",
       "1   457  1934  476\n",
       "2    44   213   86"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model2.predict(X_test)\n",
    "predict = np.argmax(predict, axis=1)\n",
    "pd.DataFrame(confusion_matrix(predict, y_test), columns=[0, 1,2], index=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      3309\n",
      "           1       0.78      0.67      0.72      2867\n",
      "           2       0.14      0.25      0.18       343\n",
      "\n",
      "    accuracy                           0.76      6519\n",
      "   macro avg       0.59      0.60      0.59      6519\n",
      "weighted avg       0.79      0.76      0.77      6519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
